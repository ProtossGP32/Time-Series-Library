{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0fe338",
   "metadata": {},
   "source": [
    "Here would go all data preparation but it was lost. Yet we still have the final csv's so we will initially not focus on recovering this code.\n",
    "\n",
    "For general idea, the code did:\n",
    "- reorder the data structure from wide to long.\n",
    "- Boxplotted each of the features separating by node_id's groups and app_user.\n",
    "- Cleaned outliers by clipping to 2.5-97.5th percentiles. \n",
    "    - Yet some combinations of feature x node x app user did not have variation while others had plenty. To solve this, we first calculate the Coefficient of Variation CV from each feature x node x app users. Then we filter out the ones without variation and check outliers on the others.\n",
    "- After that we created pairs src node id vs tgt node id. But we want to pair \"similar usage\" samples.\n",
    "    - In each app user x node x feature there is a wide distribution of values, from high usage to low usage.\n",
    "    - We create a score based on quartiles. One fore node and one for app.\n",
    "        - Take 1 sample, we do a weighted score of the position of the sample within the distribution (40% CPU, 30% energy, 30% power.) When the feature x node x app user has a small CV, we just set it to mid. 50%\n",
    "        - Then choose high/mid/low utilization depending of >66%>33%>0.\n",
    "    - Finally take this score do all possible combinations:\n",
    "        - Node A with Node B high&mid vs highmid / highlow vs highlow / highhigh vs highhigh.\n",
    "        - Node B with Node A ...\n",
    "This is the final dataset.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14981220",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
