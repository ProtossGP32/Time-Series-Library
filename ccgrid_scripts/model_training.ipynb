{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b1aca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1058cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/home/jolivera/Documents/CloudSkin/Time-Series-Library/ccgrid_scripts/data/training_data_scored_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7baadf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split function stays as is\n",
    "def split_by_app_user(df, train_users, val_users, test_users):\n",
    "    train_df = df[df[\"torchserve_app_user\"].isin(train_users)].copy()\n",
    "    val_df   = df[df[\"torchserve_app_user\"].isin(val_users)].copy()\n",
    "    test_df  = df[df[\"torchserve_app_user\"].isin(test_users)].copy()\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "# Calculate percentages\n",
    "def calculate_split_percentages(train_df, val_df, test_df):\n",
    "    total = len(train_df) + len(val_df) + len(test_df)\n",
    "    return {\n",
    "        \"train_pct\": len(train_df) / total * 100,\n",
    "        \"val_pct\": len(val_df) / total * 100,\n",
    "        \"test_pct\": len(test_df) / total * 100,\n",
    "        \"train_rows\": len(train_df),\n",
    "        \"val_rows\": len(val_df),\n",
    "        \"test_rows\": len(test_df),\n",
    "        \"total_rows\": total\n",
    "    }\n",
    "\n",
    "# Create X and y splits\n",
    "def make_xy(df):\n",
    "    X = df[[\n",
    "        \"torchserve_app_user\",\n",
    "        \"node_id_src\",\n",
    "        \"node_id_tgt\",\n",
    "        # all source metrics\n",
    "        \"torchserve_node_cpu_src\",\n",
    "        \"torchserve_node_energy_src\",\n",
    "        \"torchserve_node_power_src\",\n",
    "        \"torchserve_app_cpu_src\",\n",
    "        \"torchserve_app_energy_src\",\n",
    "        \"torchserve_app_power_src\",\n",
    "        \"torchserve_app_latency_src\",\n",
    "        \"torchserve_app_qps_src\"\n",
    "    ]].copy()\n",
    "\n",
    "    y = df[[\n",
    "        \"torchserve_node_cpu_tgt\",\n",
    "        \"torchserve_node_energy_tgt\",\n",
    "        \"torchserve_node_power_tgt\",\n",
    "        \"torchserve_app_cpu_tgt\",\n",
    "        \"torchserve_app_energy_tgt\",\n",
    "        \"torchserve_app_power_tgt\",\n",
    "        \"torchserve_app_latency_tgt\",\n",
    "        \"torchserve_app_qps_tgt\"\n",
    "    ]].copy()\n",
    "    return X, y\n",
    "\n",
    "def shuffle_df(X, y, random_state=42):\n",
    "    shuffled_idx = X.sample(frac=1, random_state=random_state).index\n",
    "    return X.loc[shuffled_idx].reset_index(drop=True), y.loc[shuffled_idx].reset_index(drop=True)\n",
    "\n",
    "def evaluate_model(model, X_val, y_val, plot=False):\n",
    "    \"\"\"\n",
    "    Evaluate a multi-output regression model on validation data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : fitted sklearn-like regressor\n",
    "    X_val : array-like\n",
    "    y_val : pd.DataFrame\n",
    "    plot : bool, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    targets = list(y_val.columns)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    if isinstance(y_pred, list):\n",
    "        y_pred = np.column_stack(y_pred)\n",
    "\n",
    "    results, r2_list, mae_list, rmse_list, mape_list = [], [], [], [], []\n",
    "\n",
    "    for i, target in enumerate(targets):\n",
    "        y_true_t = y_val[target].values\n",
    "        y_pred_t = y_pred[:, i]\n",
    "\n",
    "        r2 = r2_score(y_true_t, y_pred_t)\n",
    "        mae = mean_absolute_error(y_true_t, y_pred_t)\n",
    "        rmse = mean_squared_error(y_true_t, y_pred_t, squared=False)\n",
    "        # Compute MAPE safely\n",
    "        mape = np.mean(np.abs((y_true_t - y_pred_t) / np.where(y_true_t==0, 1e-8, y_true_t))) * 100\n",
    "\n",
    "        results.append([target, r2, mae, rmse, mape])\n",
    "        r2_list.append(r2)\n",
    "        mae_list.append(mae)\n",
    "        rmse_list.append(rmse)\n",
    "        mape_list.append(mape)\n",
    "\n",
    "        if plot:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "            fig.suptitle(target, fontsize=13)\n",
    "\n",
    "            axes[0].scatter(y_true_t, y_pred_t, alpha=0.6)\n",
    "            axes[0].plot([y_true_t.min(), y_true_t.max()],\n",
    "                         [y_true_t.min(), y_true_t.max()], 'r--', lw=1)\n",
    "            axes[0].set_xlabel(\"Actual\")\n",
    "            axes[0].set_ylabel(\"Predicted\")\n",
    "            axes[0].set_title(\"Predicted vs Actual\")\n",
    "\n",
    "            residuals = y_true_t - y_pred_t\n",
    "            axes[1].scatter(y_pred_t, residuals, alpha=0.6)\n",
    "            axes[1].axhline(0, color='red', linestyle='--', lw=1)\n",
    "            axes[1].set_xlabel(\"Predicted\")\n",
    "            axes[1].set_ylabel(\"Residual\")\n",
    "            axes[1].set_title(\"Residuals vs Predicted\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    overall_r2_mean = np.mean(r2_list)\n",
    "    overall_r2_global = r2_score(y_val, y_pred)\n",
    "    overall_mae = np.mean(mae_list)\n",
    "    overall_rmse = np.mean(rmse_list)\n",
    "    overall_mape = np.mean(mape_list)\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=[\"Target\", \"R2\", \"MAE\", \"RMSE\", \"MAPE\"])\n",
    "    overall_row = pd.DataFrame({\n",
    "        \"Target\": [\"Overall (mean)\", \"Overall (global)\"],\n",
    "        \"R2\": [overall_r2_mean, overall_r2_global],\n",
    "        \"MAE\": [overall_mae, None],\n",
    "        \"RMSE\": [overall_rmse, None],\n",
    "        \"MAPE\": [overall_mape, None]\n",
    "    })\n",
    "    results_df = pd.concat([results_df, overall_row], ignore_index=True)\n",
    "\n",
    "    print(results_df)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd65d36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_pct': 58.77706732577508, 'val_pct': 21.147247787406833, 'test_pct': 20.075684886818088, 'train_rows': 153146, 'val_rows': 55100, 'test_rows': 52308, 'total_rows': 260554}\n",
      "Shapes:\n",
      "X_train: (153146, 11) y_train: (153146, 8)\n",
      "X_val: (55100, 11) y_val: (55100, 8)\n",
      "X_test: (52308, 11) y_test: (52308, 8)\n"
     ]
    }
   ],
   "source": [
    "# Apply\n",
    "\n",
    "train_users = [1, 13, 25, 31, 43, 55]\n",
    "val_users   = [7, 19]\n",
    "test_users  = [37, 49]\n",
    "\n",
    "\n",
    "train_df, val_df, test_df = split_by_app_user(df, train_users, val_users, test_users)\n",
    "\n",
    "stats = calculate_split_percentages(train_df, val_df, test_df)\n",
    "print(stats)\n",
    "\n",
    "X_train, y_train = make_xy(train_df)\n",
    "X_val, y_val     = make_xy(val_df)\n",
    "X_test, y_test   = make_xy(test_df)\n",
    "\n",
    "X_train, y_train = shuffle_df(X_train, y_train)\n",
    "X_val, y_val     = shuffle_df(X_val, y_val)\n",
    "X_test, y_test   = shuffle_df(X_test, y_test)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val:\", X_val.shape, \"y_val:\", y_val.shape)\n",
    "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95397409",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode=1\n",
    "model_name=\"random_forest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ff72f6",
   "metadata": {},
   "source": [
    "# First model: Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b1b1b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf =RandomForestRegressor(\n",
    "#         n_estimators=200,\n",
    "#         max_depth=None,\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1\n",
    "#     )\n",
    "\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Train R^2:\", rf.score(X_train, y_train))\n",
    "# print(\"Val R^2:\", rf.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e737d3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model Val R^2: 0.8393735987692135\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # save the trained model\n",
    "# joblib.dump(rf, f\"./models/{model_name}_multioutput_scoredpairs.pkl\")\n",
    "\n",
    "# later, load it back\n",
    "rf_loaded = joblib.load(f\"./models/{model_name}_multioutput_scoredpairs.pkl\")\n",
    "\n",
    "# check it's working\n",
    "print(\"Loaded model Val R^2:\", rf_loaded.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7bbaf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Target        R2         MAE        RMSE       MAPE\n",
      "0     torchserve_node_cpu_tgt  0.879076  246.770442  329.942019  11.052893\n",
      "1  torchserve_node_energy_tgt  0.992894  214.542408  335.907626   5.597639\n",
      "2   torchserve_node_power_tgt  0.988198    4.834819    7.109354   6.553331\n",
      "3      torchserve_app_cpu_tgt  0.892616  272.062274  356.213509  16.923628\n",
      "4   torchserve_app_energy_tgt  0.904240  238.149185  358.747759  16.686388\n",
      "5    torchserve_app_power_tgt  0.899360    4.574169    7.058053  17.845120\n",
      "6  torchserve_app_latency_tgt  0.332441   15.968049   23.495710  16.310640\n",
      "7      torchserve_app_qps_tgt  0.826164    4.552061    6.048523  18.730480\n",
      "8              Overall (mean)  0.839374  125.181676  178.065319  13.712515\n",
      "9            Overall (global)  0.839374         NaN         NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "results_df = evaluate_model(rf_loaded, X_val, y_val, plot=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21343cd7",
   "metadata": {},
   "source": [
    "# XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e703112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define model\n",
    "# base_xgb = XGBRegressor(\n",
    "#     n_estimators=300,\n",
    "#     learning_rate=0.01,\n",
    "#     max_depth=6,\n",
    "#     subsample=0.8,\n",
    "#     colsample_bytree=0.8,\n",
    "#     objective='reg:squarederror',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "#     enable_categorical=True\n",
    "# )\n",
    "\n",
    "# # Wrap for multi-output regression\n",
    "# xgb_multi = MultiOutputRegressor(base_xgb)\n",
    "\n",
    "# # Fit\n",
    "# xgb_multi.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cc31914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model Val R^2: -0.8868972836132697\n"
     ]
    }
   ],
   "source": [
    "# # save the trained model\n",
    "model_name = \"xgb_multi\"\n",
    "# joblib.dump(xgb_multi, f\"./models/{model_name}_multioutput_scoredpairs.pkl\")\n",
    "\n",
    "# later, load it back\n",
    "xgb_multi_loaded = joblib.load(f\"./models/{model_name}_multioutput_scoredpairs.pkl\")\n",
    "\n",
    "# check it's working\n",
    "print(\"Loaded model Val R^2:\", xgb_multi_loaded.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0235c333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Target        R2          MAE         RMSE        MAPE\n",
      "0     torchserve_node_cpu_tgt -0.046240   801.032126   970.502804   31.722424\n",
      "1  torchserve_node_energy_tgt -1.816044  6111.776858  6687.079668  144.751315\n",
      "2   torchserve_node_power_tgt -1.839168   100.568310   110.266388  137.350180\n",
      "3      torchserve_app_cpu_tgt -0.038272   957.221580  1107.632075   47.729577\n",
      "4   torchserve_app_energy_tgt -1.074274  1433.733047  1669.669400  113.065229\n",
      "5    torchserve_app_power_tgt -0.946045    26.448835    31.036710  107.510537\n",
      "6  torchserve_app_latency_tgt -1.850668    39.665199    48.553123   43.963984\n",
      "7      torchserve_app_qps_tgt  0.515532     9.394704    10.097453   38.701366\n",
      "8              Overall (mean) -0.886897  1184.980082  1329.354702   83.099327\n",
      "9            Overall (global) -0.886897          NaN          NaN         NaN\n"
     ]
    }
   ],
   "source": [
    "results_df = evaluate_model(xgb_multi_loaded, X_val, y_val, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcad717",
   "metadata": {},
   "source": [
    "# Neural Networks: MLP\n",
    "### First Scaling and onehotencoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f02039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numeric features\n",
    "cat_features = [\"node_id_src\", \"node_id_tgt\"]\n",
    "num_features = [col for col in X_train.columns if col not in cat_features]\n",
    "\n",
    "# --- 1. One-hot encode categorical features ---\n",
    "# Fit only on train to avoid data leakage\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "encoder.fit(X_train[cat_features])\n",
    "\n",
    "# Transform each split\n",
    "X_train_cat = pd.DataFrame(\n",
    "    encoder.transform(X_train[cat_features]),\n",
    "    columns=encoder.get_feature_names_out(cat_features),\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_val_cat = pd.DataFrame(\n",
    "    encoder.transform(X_val[cat_features]),\n",
    "    columns=encoder.get_feature_names_out(cat_features),\n",
    "    index=X_val.index\n",
    ")\n",
    "\n",
    "X_test_cat = pd.DataFrame(\n",
    "    encoder.transform(X_test[cat_features]),\n",
    "    columns=encoder.get_feature_names_out(cat_features),\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# --- 2. Scale numeric features ---\n",
    "x_scaler = MinMaxScaler()\n",
    "x_scaler.fit(X_train[num_features])\n",
    "\n",
    "X_train_num = pd.DataFrame(\n",
    "    x_scaler.transform(X_train[num_features]),\n",
    "    columns=num_features,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_val_num = pd.DataFrame(\n",
    "    x_scaler.transform(X_val[num_features]),\n",
    "    columns=num_features,\n",
    "    index=X_val.index\n",
    ")\n",
    "\n",
    "X_test_num = pd.DataFrame(\n",
    "    x_scaler.transform(X_test[num_features]),\n",
    "    columns=num_features,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# --- 3. Combine scaled numeric + encoded categorical ---\n",
    "X_train_prepared = pd.concat([X_train_num, X_train_cat], axis=1)\n",
    "X_val_prepared = pd.concat([X_val_num, X_val_cat], axis=1)\n",
    "X_test_prepared = pd.concat([X_test_num, X_test_cat], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a0dce6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4417431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the MLP model\n",
    "# mlp = MLPRegressor(\n",
    "#     hidden_layer_sizes=(128, 64, 32),  # 3 hidden layers\n",
    "#     activation='relu',\n",
    "#     solver='adam',\n",
    "#     learning_rate_init=0.005,\n",
    "#     max_iter=1000,\n",
    "#     early_stopping=True,\n",
    "#     random_state=42,\n",
    "#     verbose=True\n",
    "# )\n",
    "# mlp.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ba79664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model Val R^2: 0.9308998725764865\n"
     ]
    }
   ],
   "source": [
    "# # save the trained model\n",
    "model_name = \"mlp\"\n",
    "# joblib.dump(mlp, f\"./models/{model_name}_multioutput_scoredpairs_scaled_onehotencoded.pkl\")\n",
    "\n",
    "# later, load it back\n",
    "mlp_loaded = joblib.load(f\"./models/{model_name}_multioutput_scoredpairs_scaled_onehotencoded.pkl\")\n",
    "\n",
    "# check it's working\n",
    "print(\"Loaded model Val R^2:\", mlp_loaded.score(X_val_prepared, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f86cd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Target        R2         MAE        RMSE       MAPE\n",
      "0     torchserve_node_cpu_tgt  0.975790  108.554187  147.630252   4.557416\n",
      "1  torchserve_node_energy_tgt  0.998808   93.330054  137.606355   2.371705\n",
      "2   torchserve_node_power_tgt  0.997677    2.415919    3.154028   2.995235\n",
      "3      torchserve_app_cpu_tgt  0.983586  103.212113  139.268672   5.720266\n",
      "4   torchserve_app_energy_tgt  0.974583  133.752236  184.823212   9.460074\n",
      "5    torchserve_app_power_tgt  0.966447    3.001484    4.075375  11.151755\n",
      "6  torchserve_app_latency_tgt  0.611905   14.510211   17.914838  14.700600\n",
      "7      torchserve_app_qps_tgt  0.938404    2.904102    3.600452   9.311910\n",
      "8              Overall (mean)  0.930900   57.710038   79.759148   7.533620\n",
      "9            Overall (global)  0.930900         NaN         NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "results_df = evaluate_model(mlp_loaded, X_val_prepared, y_val, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1341d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {\n",
    "#     'hidden_layer_sizes': [(128,64,32), (256,128,64), (128,128,64,32)],\n",
    "#     'activation': ['relu', 'tanh'],\n",
    "#     'learning_rate_init': [0.001, 0.003, 0.005],\n",
    "#     'alpha': [0.0001, 0.001, 0.01]\n",
    "# }\n",
    "\n",
    "# mlp_base = MLPRegressor(max_iter=1000, early_stopping=True, random_state=42)\n",
    "\n",
    "# grid = GridSearchCV(mlp_base, param_grid, cv=3, scoring='r2', n_jobs=-1, verbose=2)\n",
    "# grid.fit(X_train_prepared, y_train)\n",
    "\n",
    "# print(\"Best parameters:\", grid.best_params_)\n",
    "# print(\"Best CV R2:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0f8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compare_models_cloudskin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
